{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import Preprocess\n",
    "from training import Server\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from utils import accuracy\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configs for Single and Multi proxy models\n",
    "config_yml_M = \"config-8k-M.yml\"\n",
    "config_yml_S = \"config-8k-S.yml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-proxy training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle path:  data/tc_M_flowlen-100.pkl ; h5 path:  data/tc_M_flowlen-100_neg-49_cv-5.h5\n",
      "Cross-val in 5 folds\n",
      "Folds h5 already exists: data/tc_M_flowlen-100_neg-49_cv-5.h5\n",
      "data/tc_M_flowlen-100_neg-49_cv-5_indices.pkl exists already.\n"
     ]
    }
   ],
   "source": [
    "# Get the data ready for training\n",
    "p = Preprocess(config_yml=config_yml_M)\n",
    "p.main_run_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross-validation with seed 10\n"
     ]
    }
   ],
   "source": [
    "seeds = [1, 10, 101, 102] # seeds\n",
    "\n",
    "run = seeds[1] # 10\n",
    "\n",
    "folds = range(p.folds)\n",
    "\n",
    "print(f\"{p.folds}-fold cross-validation with seed {run}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "for fold in folds:\n",
    "    print(f\"Evaluating multi-proxy fold {fold}...\")\n",
    "    t = Server(cf=config_yml_M, fold=fold, run=run)\n",
    "    t.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_best_stats(pkl_path, fold=0):\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        aux = pickle.load(f)\n",
    "        print(round(aux[\"best_av_prec\"]*100, 2), \"epoch\", aux[\"best_av_prec_epoch\"])\n",
    "\n",
    "# Check best results on validation data\n",
    "for run in seeds:\n",
    "    print(\"Run with seed\", run)\n",
    "    try:\n",
    "        for fold in folds:\n",
    "            last_aux_path = t.last_aux.split(\"fold\")[0] + f\"fold{fold}-{run}.pkl\"\n",
    "            print_best_stats(last_aux_path, fold) \n",
    "    except FileNotFoundError:\n",
    "            print(\"No results saved.\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-proxy training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data ready for training\n",
    "p = Preprocess(config_yml=config_yml_S)\n",
    "p.main_run_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [1, 10, 101, 102] # seeds\n",
    "\n",
    "run = seeds[1] # 10\n",
    "\n",
    "folds = range(p.folds)\n",
    "\n",
    "print(f\"{p.folds}-fold cross-validation with seed {run}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "for fold in folds:\n",
    "    print(f\"Evaluating single-proxy fold {fold}...\")\n",
    "    t = Server(cf=config_yml_S, fold=fold, run=run)\n",
    "    t.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check best results on validation data\n",
    "for run in seeds:\n",
    "    print(\"Run with seed\", run)\n",
    "    try:\n",
    "        for fold in folds:\n",
    "            last_aux_path = t.last_aux.split(\"fold\")[0] + f\"fold{fold}-{run}.pkl\"\n",
    "            print_best_stats(last_aux_path, fold) \n",
    "    except FileNotFoundError:\n",
    "            print(\"No results saved.\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on N * N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(server, x, y, save_props=True, batch_size=256):\n",
    "\n",
    "    n_steps = int(np.ceil(len(x)/batch_size)) #(len(x) // 256)-1\n",
    "    print(n_steps)\n",
    "    sum_loss = 0\n",
    "    sum_acc = 0\n",
    "    if save_props:\n",
    "            saved_props = []\n",
    "            saved_y_truth = []            \n",
    "    for i in tqdm(range(n_steps)):\n",
    "        if len(y[i*256:]) >= 256:\n",
    "            xxx = tf.constant(x[i*256:(i+1)*256].astype('float32'))\n",
    "            yyy = tf.constant(y[i*256:(i+1)*256].astype('float32'))\n",
    "        else:\n",
    "            xxx = tf.constant(x[i*256:].astype('float32'))\n",
    "            yyy = tf.constant(y[i*256:].astype('float32'))\n",
    "        props = server.model(xxx, training=False)\n",
    "        props = tf.reshape(props, [-1]) # specific for tf.nn.sigmoid_cross_entropy_with_logits\n",
    "        sum_loss += server.loss(props, yyy).numpy()\n",
    "        if save_props:\n",
    "            saved_props = np.hstack([saved_props, props.numpy()])\n",
    "            saved_y_truth = np.hstack([saved_y_truth, yyy.numpy()])\n",
    "    avg_loss = round(sum_loss / n_steps, 3)\n",
    "    if save_props:\n",
    "        return avg_loss, saved_props, saved_y_truth\n",
    "    else:\n",
    "        return avg_loss\n",
    "\n",
    "\n",
    "def get_xy(test_pos_x):\n",
    "        n_pos = len(test_pos_x)\n",
    "        n_neg_per_pos = len(test_pos_x)-1\n",
    "        n_flows = n_neg_per_pos * n_pos\n",
    "        flow_size = 300\n",
    "        mod = n_neg_per_pos\n",
    "        neg_x = np.zeros((n_flows, 8, flow_size, 1), dtype=np.float32)\n",
    "        print(neg_x.shape)\n",
    "        neg_y = np.zeros((n_flows))\n",
    "        dataset = test_pos_x\n",
    "        \n",
    "        for i in tqdm(range(n_pos), desc='Generating neg test x'):\n",
    "            #print(i)\n",
    "            indices = list(range(n_pos))\n",
    "            unpaired = indices[:i] + indices[i+1:]\n",
    "            #shuffle(unpaired)\n",
    "            for j in range(n_neg_per_pos):\n",
    "                index = mod*i + j\n",
    "                #print(\"   \", index)\n",
    "                \n",
    "                down_here_time = dataset[unpaired[j]][0]\n",
    "                down_there_time = dataset[i][1]\n",
    "                up_there_time = dataset[i][2]\n",
    "                up_here_time = dataset[unpaired[j]][3]\n",
    "\n",
    "                down_here_size = dataset[unpaired[j]][4]\n",
    "                down_there_size = dataset[i][5]\n",
    "                up_there_size = dataset[i][6]\n",
    "                up_here_size = dataset[unpaired[j]][7]\n",
    "\n",
    "                neg_x[index, 0, :,] = down_here_time\n",
    "                neg_x[index, 1, :,] = down_there_time\n",
    "                neg_x[index, 2, :,] = up_there_time\n",
    "                neg_x[index, 3, :,] = up_here_time\n",
    "\n",
    "                neg_x[index, 4, :,] = down_here_size\n",
    "                neg_x[index, 5, :,] = down_there_size\n",
    "                neg_x[index, 6, :,] = up_there_size\n",
    "                neg_x[index, 7, :,] = up_here_size\n",
    "        return neg_x, neg_y\n",
    "    \n",
    "    \n",
    "def makeNtimesN(h5_path, fold=-1):\n",
    "    print(f\"MAKE N*N TESTING\")\n",
    "    \n",
    "    if fold >= 0:\n",
    "        print(f\"Fold {fold}\")\n",
    "\n",
    "    with h5py.File(h5_path, 'r') as h5f:\n",
    "        if fold >= 0:\n",
    "            test_indices = list(h5f['indices'][f'test{fold}'])\n",
    "        else:\n",
    "            test_indices = list(h5f['indices']['test'])\n",
    "        x = list(h5f['data']['x'])\n",
    "        y = list(h5f['data']['y'])\n",
    "\n",
    "    test_x = [x[index] for index in test_indices]\n",
    "    test_y = [y[index] for index in test_indices]\n",
    "    print(\"Test X:\", len(test_x))\n",
    "\n",
    "    test_pos_x = [test_x[i] for i in range(len(test_x)) if test_y[i] == 1]\n",
    "    test_pos_y = [y for y in test_y if y == 1]\n",
    "\n",
    "    test_flows = len(test_pos_x) * len(test_pos_x) \n",
    "    n_flows = (len(test_pos_x)-1)*len(test_pos_x)\n",
    "    flow_size = 300\n",
    "\n",
    "    test_neg_x, test_neg_y = get_xy(test_pos_x)\n",
    "\n",
    "    print(\"Positive samples: \", len(test_pos_x))\n",
    "    print(\"Negative samples: \", len(test_neg_x))\n",
    "    print(\"N*N=\", len(test_pos_x)*len(test_pos_x))\n",
    "\n",
    "    test_x = np.concatenate((test_pos_x, test_neg_x), axis=0)\n",
    "    test_y = np.concatenate((test_pos_y, test_neg_y), axis=0)\n",
    "    print(test_x.shape, test_y.shape)\n",
    "    \n",
    "    return test_x, test_y\n",
    "\n",
    "\n",
    "def save_results(props, y_truth, name):\n",
    "    res = [props, y_truth]\n",
    "    name = \"results/\" + name + \".pkl\"\n",
    "    pickle.dump(res, open(name, \"wb\"))\n",
    "    print(\"Saved: \" + name)\n",
    "    \n",
    "    \n",
    "def load_results(name):\n",
    "    name = name + \".pkl\"\n",
    "    res = pickle.load(open(name, \"rb\"))\n",
    "    print(len(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_datapath_S = \"log_tc_S_neg-49/test/test_tc_S_NtimesN\"\n",
    "#test_datapath_M = \"log_tc_M_neg-49/test/test_tc_M_NtimesN\"\n",
    "\n",
    "h5_path_S = \"data/tc_S_flowlen-100_neg-49_cv-5.h5\"\n",
    "h5_path_M = \"data/tc_M_flowlen-100_neg-49_cv-5.h5\"\n",
    "\n",
    "res_S = \"results/test_tc_S_flowlen-100_neg-49_NtimesN\"\n",
    "res_M = \"results/test_tc_M_flowlen-100_neg-49_NtimesN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will generate N * N datasets for single and multi proxy models for each fold (5 times), and then test a model for every fold on this new test dataset. This takes a very long time.\n",
    "\n",
    "We already provide final results in the folder \"results/\", that are generated with this code with seed=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [run] # = seeds\n",
    "\n",
    "res = {}\n",
    "save = True\n",
    "\n",
    "print(\"Test Multi-proxy:\")\n",
    "for fold in folds:\n",
    "    test_x, test_y = makeNtimesN(h5_path_M, fold=fold)\n",
    "    #name = test_datapath_M + f\"fold{fold}.pkl\"\n",
    "    #[test_x, test_y] = pickle.load(open(name, \"rb\"))\n",
    "    for run in runs:\n",
    "        print(f\"Fold {fold}, run {run}...\", end='')\n",
    "\n",
    "        t = Server(cf=config_yml_S, fold=fold, run=run, pred_only=True, init_data=False)\n",
    "\n",
    "        loss, props, y_truth = predict(t, test_x, test_y)\n",
    "        av_prec = average_precision_score(y_truth, props)\n",
    "\n",
    "        print(f\"AP = {av_prec}\")\n",
    "\n",
    "        if save:\n",
    "            res_path = res_M + f\"-fold{fold}-run{run}\" \n",
    "            save_results(props, y_truth, res_path\")\n",
    "            print(f\"Results saved at\", res_path)\n",
    "\n",
    "        del t\n",
    "    del test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [run] # = seeds\n",
    "\n",
    "res = {}\n",
    "save = True\n",
    "\n",
    "print(\"Test Single-proxy:\")\n",
    "for fold in folds:\n",
    "    test_x, test_y = makeNtimesN(h5_path_S, fold=fold)\n",
    "    #name = test_datapath_S + f\"fold{fold}.pkl\"\n",
    "    #[test_x, test_y] = pickle.load(open(name, \"rb\"))\n",
    "    for run in runs:\n",
    "        print(f\"Fold {fold}, run {run}...\", end='')\n",
    "\n",
    "        t = Server(cf=config_yml_S, fold=fold, run=run, pred_only=True, init_data=False)\n",
    "\n",
    "        loss, props, y_truth = predict(t, test_x, test_y)\n",
    "        av_prec = average_precision_score(y_truth, props)\n",
    "\n",
    "        print(f\"AP = {av_prec}\")\n",
    "\n",
    "        if save:\n",
    "            res_path = res_S + f\"-fold{fold}-run{run}\" \n",
    "            save_results(props, y_truth, res_path\")\n",
    "            print(f\"Results saved at\", res_path)\n",
    "\n",
    "        del t\n",
    "    del test_x, test_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
